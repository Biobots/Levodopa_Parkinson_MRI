{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import os.path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5773/196695917.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_u3_score = pd.read_csv(os.path.join('..', 'data', 'csv', 'MDS_UPDRS_Part_III_CAL.csv'))\n"
     ]
    }
   ],
   "source": [
    "raw_age_at_visit = pd.read_csv(os.path.join('..', 'data', 'csv', 'Age_at_visit.csv'))\n",
    "raw_u3_score = pd.read_csv(os.path.join('..', 'data', 'csv', 'MDS_UPDRS_Part_III_CAL.csv'))\n",
    "#Deprecated\n",
    "#raw_u3_on_off = pd.read_csv(os.path.join('..', 'data', 'csv', 'MDS-UPDRS_Part_III_ON_OFF_Determination___Dosing.csv'))\n",
    "raw_demographic = pd.read_csv(os.path.join('..', 'data', 'csv', 'Demographics.csv'))\n",
    "raw_img_info = pd.read_csv(os.path.join('..', 'data', 'T1PD.csv'))\n",
    "raw_diag = pd.read_csv(os.path.join('..', 'data', 'csv', 'PD_Diagnosis_History.csv'))\n",
    "raw_ledd = pd.read_csv(os.path.join('..', 'data', 'csv', 'LEDD_Concomitant_Medication_Log.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(x):\n",
    "    # MED_ON\n",
    "    on_score = list(x[x['PDSTATE'] == 'ON']['NP3TOT'])\n",
    "    if len(on_score) == 0:\n",
    "        on_score = [None]\n",
    "    # MED_OFF\n",
    "    off_score = list(x[x['PDSTATE'] == 'OFF']['NP3TOT'])\n",
    "    if len(off_score) == 0:\n",
    "        off_score = [None]\n",
    "    return pd.Series({'INFODT': list(x['INFODT'])[0], 'NUPDR3OF': off_score[0], 'NUPDR3ON': on_score[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep duplicate index\n",
    "u3_dup_idx = raw_u3_score.duplicated(subset=['PATNO', 'EVENT_ID'], keep=False)\n",
    "# Get duplicate records\n",
    "u3_rec = raw_u3_score[u3_dup_idx][['PATNO', 'EVENT_ID', 'INFODT', 'PDSTATE', 'NP3TOT']].dropna().reset_index(drop=True)\n",
    "# Generate U3 ON/OFF records by PATNO and EVENT_ID\n",
    "u3_rec = u3_rec.groupby(['PATNO', 'EVENT_ID']).apply(apply_filter).reset_index().dropna().reset_index(drop=True)\n",
    "# Get image id\n",
    "image_meta = raw_img_info.rename(columns={'Image Data ID': 'IMG_ID', 'Subject': 'PATNO', 'Visit': 'EVENT_ID'})\n",
    "# Merge U3 records and image id\n",
    "data = pd.merge(u3_rec, image_meta, on=['PATNO', 'EVENT_ID'])[['PATNO', 'EVENT_ID', 'INFODT', 'NUPDR3OF', 'NUPDR3ON', 'IMG_ID']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image metadata file path\n",
    "xmllist = []\n",
    "for dirpath, dirnames, filenames in os.walk(os.path.join('..', 't1meta')):\n",
    "    for filename in filenames:\n",
    "        if dirpath == os.path.join('..', 't1meta'):\n",
    "            continue\n",
    "        xmllist.append(os.path.join(dirpath, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate image dataframe by PATNO and IMG_ID\n",
    "img_path = []\n",
    "from xml.dom import minidom\n",
    "for xml in xmllist:\n",
    "    root = minidom.parse(xml).documentElement\n",
    "    subject = root.getElementsByTagName('subject')[0].getAttribute('id')\n",
    "    study = root.getElementsByTagName('study')[0].getAttribute('uid')\n",
    "    series = root.getElementsByTagName('series')[0].getAttribute('uid')\n",
    "    image = root.getElementsByTagName('image')[0].getAttribute('uid')\n",
    "    relative_path = os.path.join(xml.split(os.sep)[2], xml.split(os.sep)[3], xml.split(os.sep)[4], series)\n",
    "    img_path.append({'PATNO': int(subject), 'IMG_ID': str(image), 'SERIES': str(series), 'IMG_REL_PATH': str(relative_path)})\n",
    "img_path = pd.DataFrame(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge image df and main df\n",
    "data = pd.merge(data, img_path, on=['PATNO', 'IMG_ID'])[['PATNO', 'EVENT_ID', 'INFODT', 'NUPDR3OF', 'NUPDR3ON', 'IMG_ID', 'IMG_REL_PATH']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge age_at_visit df and main df to extract age by EVENT_ID\n",
    "data = pd.merge(data, raw_age_at_visit, on=['PATNO', 'EVENT_ID'])[['PATNO', 'EVENT_ID', 'INFODT', 'NUPDR3OF', 'NUPDR3ON', 'IMG_ID', 'IMG_REL_PATH', 'AGE_AT_VISIT']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge demographic df and main df\n",
    "data = pd.merge(data, raw_demographic.drop(labels=['EVENT_ID', 'INFODT'], axis=1), on=['PATNO'])[['PATNO', 'EVENT_ID', 'INFODT', 'NUPDR3OF', 'NUPDR3ON', 'IMG_ID', 'IMG_REL_PATH', 'AGE_AT_VISIT', 'SEX', 'ORIG_ENTRY']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration calculation function\n",
    "def get_duration(rec):\n",
    "    visit = rec.EVENT_ID\n",
    "    id = rec.PATNO\n",
    "    visit = rec.INFODT\n",
    "    diag = raw_diag[raw_diag['PATNO'] == id]['PDDXDT'].iloc[0]\n",
    "    visit = visit.split('/')\n",
    "    diag = diag.split('/')\n",
    "    return 12 * (int(visit[1]) - int(diag[1])) + int(visit[0]) - int(diag[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate score\n",
    "data['SCORE'] = (data['NUPDR3OF'] - data['NUPDR3ON']) / data['NUPDR3OF']\n",
    "# Calculate duration\n",
    "data['DURATION'] = data.apply(get_duration, axis=1)\n",
    "# Calculate categories\n",
    "data['CAT'] = 1 * (data['SCORE'] >= 0.3)\n",
    "# Generate unique key\n",
    "data['KEY'] = data['PATNO'].astype(str) + data['EVENT_ID'] + data['IMG_ID']\n",
    "# Reformat INFODT\n",
    "data['INFODT'] = pd.to_datetime(data['INFODT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEDD extraction\n",
    "# ???\n",
    "ledd_rec = raw_ledd[['PATNO', 'LEDTRT', 'STARTDT', 'STOPDT', 'LEDD']].copy()\n",
    "# Convert to date\n",
    "ledd_rec['STARTDT'] = pd.to_datetime(ledd_rec['STARTDT'])\n",
    "ledd_rec['STOPDT'] = pd.to_datetime(ledd_rec['STOPDT'])\n",
    "# Fill blank stop date with current date\n",
    "ledd_rec['STOPDT'] = ledd_rec['STOPDT'].fillna(pd.Timestamp.now())\n",
    "# Drop duplicate records\n",
    "ledd_rec = ledd_rec.dropna().drop_duplicates(subset=['PATNO', 'LEDTRT', 'STARTDT', 'STOPDT', 'LEDD']).reset_index(drop=True)\n",
    "\n",
    "from functools import reduce\n",
    "def get_ledd(rec):\n",
    "    date = rec.INFODT\n",
    "    id = rec.PATNO\n",
    "    ledd_history = ledd_rec[ledd_rec['PATNO'] == id]\n",
    "    # Filter by date, records at start date are dropped\n",
    "    ledd_history = ledd_history[(ledd_history['STARTDT'] < date) & (ledd_history['STOPDT'] >= date)]\n",
    "    ledd_list = ledd_history['LEDD']\n",
    "    # Check if value is float\n",
    "    ledd_isfloat = list(map(lambda x: x.replace('.','',1).isdigit(), ledd_list))\n",
    "    # Generate string index list\n",
    "    ledd_notfloat = [not e for e in ledd_isfloat]\n",
    "    ld = 0\n",
    "    # Drop records without baseline ld value\n",
    "    if len(ledd_list[ledd_isfloat]) == 0:\n",
    "        return None\n",
    "    # Sum all float values\n",
    "    ld = float(reduce(lambda x, y: float(x)+float(y), ledd_list[ledd_isfloat]))\n",
    "    # Return if no inhibitor is used\n",
    "    if len(ledd_list[ledd_notfloat]) == 0:\n",
    "        return ld\n",
    "    # Replace LD in inhibitor string with ld value\n",
    "    ledd_eval = list(map(lambda s: s.replace('LD', str(ld)), ledd_list[ledd_notfloat]))\n",
    "    # Calculate inhibitor values\n",
    "    ledd_eval = list(map(lambda s: s.replace('x', '*'), ledd_eval))\n",
    "    ledd_eval = list(map(lambda s: float(eval(s)), ledd_eval))\n",
    "    # Sum all available values\n",
    "    ld += sum(ledd_eval)\n",
    "    return ld\n",
    "\n",
    "# Get LEDD for all records\n",
    "data['LEDD'] = data.apply(get_ledd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BL value\n",
    "data.loc[data['KEY'] == '3826V04I395598', 'LEDD'] = 300 # Drop?\n",
    "data = data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATNO</th>\n",
       "      <th>NUPDR3OF</th>\n",
       "      <th>NUPDR3ON</th>\n",
       "      <th>AGE_AT_VISIT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>DURATION</th>\n",
       "      <th>CAT</th>\n",
       "      <th>LEDD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>355.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>355.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28055.949296</td>\n",
       "      <td>28.261972</td>\n",
       "      <td>19.008451</td>\n",
       "      <td>64.479155</td>\n",
       "      <td>0.636620</td>\n",
       "      <td>0.326290</td>\n",
       "      <td>46.729577</td>\n",
       "      <td>0.515493</td>\n",
       "      <td>691.401741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27988.870479</td>\n",
       "      <td>12.308492</td>\n",
       "      <td>11.121437</td>\n",
       "      <td>9.142118</td>\n",
       "      <td>0.481652</td>\n",
       "      <td>0.245535</td>\n",
       "      <td>21.703448</td>\n",
       "      <td>0.500465</td>\n",
       "      <td>498.629997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3107.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3558.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>58.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154701</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>370.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4082.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50028.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>71.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.492424</td>\n",
       "      <td>56.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>149511.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>86.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5140.450000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PATNO    NUPDR3OF    NUPDR3ON  AGE_AT_VISIT         SEX  \\\n",
       "count     355.000000  355.000000  355.000000    355.000000  355.000000   \n",
       "mean    28055.949296   28.261972   19.008451     64.479155    0.636620   \n",
       "std     27988.870479   12.308492   11.121437      9.142118    0.481652   \n",
       "min      3107.000000    2.000000    1.000000     35.100000    0.000000   \n",
       "25%      3558.000000   19.000000   11.000000     58.400000    0.000000   \n",
       "50%      4082.000000   27.000000   18.000000     65.500000    1.000000   \n",
       "75%     50028.000000   36.000000   25.000000     71.500000    1.000000   \n",
       "max    149511.000000   62.000000   64.000000     86.300000    1.000000   \n",
       "\n",
       "            SCORE    DURATION         CAT         LEDD  \n",
       "count  355.000000  355.000000  355.000000   355.000000  \n",
       "mean     0.326290   46.729577    0.515493   691.401741  \n",
       "std      0.245535   21.703448    0.500465   498.629997  \n",
       "min     -0.272727    2.000000    0.000000    30.000000  \n",
       "25%      0.154701   30.000000    0.000000   370.000000  \n",
       "50%      0.300000   51.000000    1.000000   600.000000  \n",
       "75%      0.492424   56.500000    1.000000   900.000000  \n",
       "max      0.956522  112.000000    1.000000  5140.450000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下为影像文件路径相关"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add root\n",
    "data['IMG_REL_PATH'] = '..' + os.sep + 't1raw' + os.sep + data['IMG_REL_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract nii file by path\n",
    "import shutil\n",
    "def move_nii(rec):\n",
    "    orig_path = rec.IMG_REL_PATH\n",
    "    orig_path = os.path.join(orig_path, os.listdir(rec.IMG_REL_PATH)[0])\n",
    "    dest_path = os.path.join('..', 't1', str(rec.PATNO)+str(rec.EVENT_ID)+str(rec.IMG_ID))\n",
    "    #os.mkdir(dest_path)\n",
    "    dest_path = os.path.join(dest_path, 't1.nii')\n",
    "    #shutil.copyfile(orig_path, dest_path)\n",
    "    return dest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['NII_PATH'] = data.apply(move_nii, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 't1.nii' to get IMG_ROOT\n",
    "data['IMG_ROOT'] = data['NII_PATH'].apply(lambda x: x[:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matlab code: M1Segmentation.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessed image path\n",
    "data['T1_MNI_PATH'] = data['IMG_ROOT'] + 'mri' + os.sep + 'wmt1.nii'\n",
    "data['T1_GM_PATH'] = data['IMG_ROOT'] + 'mri' + os.sep + 'mwp1t1.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matlab code: M2Smooth.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['T1_SGM_PATH'] = data['IMG_ROOT'] + 'mri' + os.sep + 'smwp1t1.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR check\n",
    "iqr_list = []\n",
    "from xml.dom import minidom\n",
    "report_list = list(data['IMG_ROOT']+ os.sep + 'report' + os.sep + 'cat_t1.xml')\n",
    "for report in report_list:\n",
    "    root = minidom.parse(report).documentElement\n",
    "    iqr_str = root.getElementsByTagName('catlog')[0].getElementsByTagName('item')[-5].childNodes[0].data\n",
    "    iqr_str = iqr_str.split(' ')[4][:-1]\n",
    "    iqr_list.append({'IQR': float(iqr_str)})\n",
    "iqr_list = pd.DataFrame(iqr_list)\n",
    "data = pd.concat([data, iqr_list], axis=1)\n",
    "data = data[data['IQR'] >= 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to json file\n",
    "data['INFODT'] = data['INFODT'].astype(str) # Datetime cant be stored in json\n",
    "data_json = data.to_dict(orient='records')\n",
    "with open('data.json', 'w+') as f:\n",
    "    json.dump(data_json, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.data import getDataPandas\n",
    "data = getDataPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "report_list = list(data['IMG_ROOT']+ 'report' + os.sep + 'cat_t1.xml')\n",
    "vol_list = []\n",
    "for report in report_list:\n",
    "    root = minidom.parse(report).documentElement\n",
    "    tiv_str = root.getElementsByTagName('subjectmeasures')[1].getElementsByTagName('vol_TIV')[0].childNodes[0].data\n",
    "    vol_str = root.getElementsByTagName('subjectmeasures')[1].getElementsByTagName('vol_abs_CGW')[0].childNodes[0].data\n",
    "    tiv = float(tiv_str)\n",
    "    gm = float(vol_str.split(' ')[1])\n",
    "    wm = float(vol_str.split(' ')[2])\n",
    "    vol_list.append({'TIV': tiv, 'GM_VOL': gm, 'WM_VOL': wm})\n",
    "vol_list = pd.DataFrame(vol_list)\n",
    "data = pd.concat([data, vol_list], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json = data.to_dict(orient='records')\n",
    "with open('data.json', 'w+') as f:\n",
    "    json.dump(data_json, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('3.8.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "420353a47962bc0cada1a6173771095a3d05bd8a3ecc61a5b633bf029926f1ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
