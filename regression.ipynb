{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "log = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = True\n",
    "writer = SummaryWriter('./log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.data import getPandas, writePandas\n",
    "data = getPandas('data')\n",
    "test = data.sample(frac=0.2, random_state=10)\n",
    "data = data.drop(test.index)\n",
    "validate = data.sample(frac=0.1, random_state=10)\n",
    "train = data.drop(validate.index)\n",
    "test = test.reset_index(drop=True)\n",
    "train = train.reset_index(drop=True)\n",
    "validate = validate.reset_index(drop=True)\n",
    "writePandas('data_test', test)\n",
    "writePandas('data_train', train)\n",
    "writePandas('data_validate', validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dl.loader import RegressDataset\n",
    "from src.dl.resnet import RegressCNN\n",
    "from sklearn.model_selection import KFold\n",
    "import collections\n",
    "train_set = RegressDataset('train')\n",
    "val_set = RegressDataset('validate')\n",
    "test_set = RegressDataset('test')\n",
    "fold_num = 5\n",
    "kf = KFold(n_splits=fold_num, shuffle=True, random_state=10)\n",
    "best_models = np.empty(dtype=collections.OrderedDict, shape=fold_num)\n",
    "net = RegressCNN().cuda()\n",
    "loss_fn = nn.SmoothL1Loss().cuda()\n",
    "#lr = 1e-2\n",
    "#optim = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "lr = 1e-3\n",
    "#optim = torch.optim.SGD([{'params': net.fc.weight, 'lr': 1e-2}], lr=lr)\n",
    "optim = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "epoch = 100\n",
    "train_loader = DataLoader(train_set, batch_size=8)\n",
    "val_loader = DataLoader(val_set, batch_size=8)\n",
    "for i in range(epoch):\n",
    "    total_loss = 0\n",
    "    predy = np.array([])\n",
    "    y = np.array([])\n",
    "    net.train()\n",
    "    for step, [img, labels, score] in enumerate(train_loader):\n",
    "        img = img.cuda()\n",
    "        labels = labels.cuda()\n",
    "        score = score.cuda()\n",
    "        output = net(img, labels).squeeze(-1)\n",
    "        loss = loss_fn(output, score)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #scheduler.step()\n",
    "        \n",
    "        output = output.cpu().detach().numpy()\n",
    "        score = score.cpu().detach().numpy()\n",
    "        predy = np.concatenate((predy, output), axis=0)\n",
    "        y = np.concatenate((y, score), axis=0)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    nmse = np.sum((y - predy) ** 2) / np.sum(y ** 2)\n",
    "    mse = np.sum((y - predy) ** 2) / len(train_set)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.sum(np.abs(y - predy)) / len(train_set)\n",
    "    meany = np.mean(y)\n",
    "    rsquared = r2_score(y, predy)\n",
    "    print('train epoch {}, loss {}, nmse {}, rmse {}, mae {}, rsquared {}'.format(i, total_loss, nmse, rmse, mae, rsquared))\n",
    "    \n",
    "    if log:\n",
    "        writer.add_scalar('train/Loss', total_loss, i)\n",
    "        writer.add_scalar('train/NMSE', nmse, i)\n",
    "        writer.add_scalar('train/RMSE', rmse, i)\n",
    "        writer.add_scalar('train/MAE', mae, i)\n",
    "        writer.add_scalar('train/rsquared', rsquared, i)\n",
    "        \n",
    "    net.eval()\n",
    "    total_loss = 0\n",
    "    predy = np.array([])\n",
    "    y = np.array([])\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for step, [img, labels, score] in enumerate(val_loader):\n",
    "            img = img.cuda()\n",
    "            labels = labels.cuda()\n",
    "            score = score.cuda()\n",
    "            output = net(img, labels).squeeze(-1)\n",
    "            loss = loss_fn(output, score)\n",
    "\n",
    "            output = output.cpu().detach().numpy()\n",
    "            score = score.cpu().detach().numpy()\n",
    "            #print(\"y: \", score)\n",
    "            #print(\"y_pred: \", output)\n",
    "            predy = np.concatenate((predy, output), axis=0)\n",
    "            y = np.concatenate((y, score), axis=0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    nmse = np.sum((y - predy) ** 2) / np.sum(y ** 2)\n",
    "    mse = np.sum((y - predy) ** 2) / len(val_set)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.sum(np.abs(y - predy)) / len(val_set)\n",
    "    meany = np.mean(y)\n",
    "    rsquared = r2_score(y, predy)\n",
    "    print('validation epoch {}, loss {}, nmse {}, rmse {}, mae {}, rsquared {}'.format(i, total_loss, nmse, rmse, mae, rsquared))\n",
    "    if log:\n",
    "        writer.add_scalar('validation/Loss', total_loss, i)\n",
    "        writer.add_scalar('validation/NMSE', nmse, i)\n",
    "        writer.add_scalar('validation/RMSE', rmse, i)\n",
    "        writer.add_scalar('validation/MAE', mae, i)\n",
    "        writer.add_scalar('validation/rsquared', rsquared, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 0, loss 1.2705457803388311, nmse 0.5820618636310471, rmse 0.3204060718967204, mae 0.2597217988753498, rsquared -0.9319191856627904\n",
      "validation epoch 0, loss 0.07125460409419046, nmse 0.4535196613114828, rmse 0.21779763927523607, mae 0.1830128508782032, rsquared -0.23640535663170903\n",
      "train epoch 1, loss 1.0372686503228414, nmse 0.475816910917891, rmse 0.28969173277289395, mae 0.23332297877917935, rsquared -0.579281991317262\n",
      "validation epoch 1, loss 0.06166337387403477, nmse 0.3884365399300048, rmse 0.2015650110663673, mae 0.1690533409210856, rsquared -0.05897287295576126\n",
      "train epoch 2, loss 0.8905752562248191, nmse 0.4092871860630559, rmse 0.2686768444095969, mae 0.21535403693768734, rsquared -0.3584634496898822\n",
      "validation epoch 2, loss 0.057590275256412395, nmse 0.35900168599532234, rmse 0.1937775016764472, mae 0.1598619233008839, rsquared 0.021273727536202824\n",
      "train epoch 3, loss 0.7962586899699644, nmse 0.3665646991316259, rmse 0.2542678697417324, mae 0.20400058945563615, rsquared -0.21666341550249402\n",
      "validation epoch 3, loss 0.05703780405471059, nmse 0.35251820761172636, rmse 0.19201974335865027, mae 0.15618231998716095, rsquared 0.03894927302391715\n",
      "train epoch 4, loss 0.7367953724241996, nmse 0.3396817365634184, rmse 0.24476666100510608, mae 0.19631992682364593, rsquared -0.12743628279019625\n",
      "validation epoch 4, loss 0.05843261611353216, nmse 0.35895659213416825, rmse 0.19376533119019046, mae 0.15567625081464856, rsquared 0.02139666441466337\n",
      "train epoch 5, loss 0.7008960895678777, nmse 0.3234977321452623, rmse 0.238864596438043, mae 0.19193153901524845, rsquared -0.07372001895315172\n",
      "validation epoch 5, loss 0.060697613691283306, nmse 0.37142570019404414, rmse 0.19710202384411588, mae 0.1564640987167172, rsquared -0.012597169398556263\n",
      "train epoch 6, loss 0.6801621815561018, nmse 0.3141908319993267, rmse 0.23540350182460723, mae 0.18910843399899202, rsquared -0.042829524188873425\n",
      "validation epoch 6, loss 0.06312356615775667, nmse 0.38535683375623075, rmse 0.20076437020513666, mae 0.15874773689060084, rsquared -0.05057684179121402\n",
      "train epoch 7, loss 0.6686479087550119, nmse 0.30905526563918573, rmse 0.23347169625174988, mae 0.187547576094057, rsquared -0.025784086581077004\n",
      "validation epoch 7, loss 0.06534263554855355, nmse 0.39833879015127716, rmse 0.20411804883515605, mae 0.16045048851626875, rsquared -0.08596882541542716\n",
      "train epoch 8, loss 0.6624616628413794, nmse 0.30632623412604304, rmse 0.23243860527717325, mae 0.1867153903303833, rsquared -0.01672616908476665\n",
      "validation epoch 8, loss 0.06714031164274037, nmse 0.40896069223752474, rmse 0.20682159920693052, mae 0.16165248328549187, rsquared -0.11492672461449649\n",
      "train epoch 9, loss 0.65909480139353, nmse 0.3048605760906647, rmse 0.23188187204472688, mae 0.18618489177798958, rsquared -0.011861509406662085\n",
      "validation epoch 9, loss 0.06856457294241348, nmse 0.41745913160330655, rmse 0.20895948582307464, mae 0.16308313970776014, rsquared -0.13809554583930717\n",
      "train epoch 10, loss 0.6572281108655078, nmse 0.30406172479283694, rmse 0.2315778631672956, mae 0.18592994683819597, rsquared -0.009210045283695178\n",
      "validation epoch 10, loss 0.06965869052878694, nmse 0.4239987607286214, rmse 0.2105898338219267, mae 0.16411362002756355, rsquared -0.15592417196224573\n",
      "train epoch 11, loss 0.6561693527554545, nmse 0.3036232454829163, rmse 0.23141082679349234, mae 0.1857903046067029, rsquared -0.0077546903733642925\n",
      "validation epoch 11, loss 0.07037512324023851, nmse 0.42833399954320167, rmse 0.21166369947166144, mae 0.16471819671277543, rsquared -0.16774309173547963\n",
      "train epoch 12, loss 0.6555968000399035, nmse 0.3033932592443412, rmse 0.23132316652925275, mae 0.18573100514824273, rsquared -0.00699134397583534\n",
      "validation epoch 12, loss 0.07097422228531092, nmse 0.4319484207830538, rmse 0.21255486691098216, mae 0.16525519121336912, rsquared -0.17759688675983099\n",
      "train epoch 13, loss 0.6552527658194086, nmse 0.3032606294652322, rmse 0.23127259900131458, mae 0.18570058243572332, rsquared -0.006551133010539667\n",
      "validation epoch 13, loss 0.07140636452612747, nmse 0.43454599184975684, rmse 0.2131930204076092, mae 0.16563864821297447, rsquared -0.18467849987405804\n",
      "train epoch 14, loss 0.6550900804845748, nmse 0.30319821803300234, rmse 0.23124879967583364, mae 0.1856867779692693, rsquared -0.0063439834773655335\n",
      "validation epoch 14, loss 0.07175287597692234, nmse 0.43663931079390744, rmse 0.21370590606879128, mae 0.16595170128989195, rsquared -0.19038539855228054\n",
      "train epoch 15, loss 0.6548872506400634, nmse 0.30312207025863597, rmse 0.2312197589590101, mae 0.18565813148540553, rsquared -0.006091241706368766\n",
      "validation epoch 15, loss 0.07196245850532373, nmse 0.4379121352648671, rmse 0.21401716087097808, mae 0.1661270229338947, rsquared -0.19385542891302743\n",
      "train epoch 16, loss 0.6547725422296442, nmse 0.3030749145705149, rmse 0.23120177321664379, mae 0.1856417143998956, rsquared -0.005934727451980093\n",
      "validation epoch 16, loss 0.07212947570496406, nmse 0.4389279997709385, rmse 0.21426525458444193, mae 0.16627411229603917, rsquared -0.19662492365397544\n",
      "train epoch 17, loss 0.6546279178916152, nmse 0.30302467898204577, rmse 0.23118261122417727, mae 0.18561858272825554, rsquared -0.005767990712759463\n",
      "validation epoch 17, loss 0.07218624446338098, nmse 0.4392926845801264, rmse 0.21435424760800365, mae 0.16632367084886787, rsquared -0.19761914350821108\n",
      "train epoch 18, loss 0.6544459902718714, nmse 0.30294565544706514, rmse 0.23115246506837253, mae 0.18559113555743756, rsquared -0.005505704016298019\n",
      "validation epoch 18, loss 0.07221536646056329, nmse 0.4394770817106082, rmse 0.21439923146790002, mae 0.16633949046345167, rsquared -0.19812185511991043\n",
      "train epoch 19, loss 0.6542389128575203, nmse 0.3028593784147242, rmse 0.23111954733466505, mae 0.18556891500731337, rsquared -0.005219342265982085\n",
      "validation epoch 19, loss 0.07225779075426886, nmse 0.439734957618309, rmse 0.21446212472284704, mae 0.16637278372151176, rsquared -0.19882488782351038\n",
      "train epoch 20, loss 0.6541114696461839, nmse 0.30280380329762774, rmse 0.23109834098260582, mae 0.18555394056927532, rsquared -0.005034883118814504\n",
      "validation epoch 20, loss 0.07228474870931537, nmse 0.4399060987001834, rmse 0.21450385407476058, mae 0.16639123135906975, rsquared -0.1992914602092748\n",
      "train epoch 21, loss 0.6539767978371049, nmse 0.3027487673055581, rmse 0.23107733843194847, mae 0.185542414597902, rsquared -0.004852213379350934\n",
      "validation epoch 21, loss 0.07235828357331309, nmse 0.440353848050308, rmse 0.21461299047328192, mae 0.16646386503733265, rsquared -0.20051213428836911\n",
      "train epoch 22, loss 0.6538771289115993, nmse 0.3027074450555382, rmse 0.23106156799383287, mae 0.18552529408541157, rsquared -0.004715060865853049\n",
      "validation epoch 22, loss 0.07234398558012496, nmse 0.4402768325916085, rmse 0.21459422233860204, mae 0.16646043912490907, rsquared -0.20030217133901385\n",
      "train epoch 23, loss 0.6537750172847491, nmse 0.3026634679772209, rmse 0.2310447831708546, mae 0.18551710489880413, rsquared -0.004569096722453203\n",
      "validation epoch 23, loss 0.07239614789181686, nmse 0.4405939323669652, rmse 0.21467148683060852, mae 0.16651418354938222, rsquared -0.20116666276966977\n",
      "train epoch 24, loss 0.6536705626561473, nmse 0.3026237895867348, rmse 0.23102963799052323, mae 0.18550080656172308, rsquared -0.0044374003365086345\n",
      "validation epoch 24, loss 0.07240541265085597, nmse 0.4406533882726893, rmse 0.21468597075353868, mae 0.1665230971530782, rsquared -0.20132875408916862\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m optim\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     26\u001b[0m \u001b[39m#scheduler.step()\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     29\u001b[0m score \u001b[39m=\u001b[39m score\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     30\u001b[0m predy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((predy, output), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.dl.loader import BlockRegressDataset\n",
    "from src.dl.resnet import RegressResNet3d\n",
    "from sklearn.model_selection import KFold\n",
    "import collections\n",
    "train_set = BlockRegressDataset('train')\n",
    "val_set = BlockRegressDataset('validate')\n",
    "test_set = BlockRegressDataset('test')\n",
    "fold_num = 5\n",
    "kf = KFold(n_splits=fold_num, shuffle=True, random_state=10)\n",
    "best_models = np.empty(dtype=collections.OrderedDict, shape=fold_num)\n",
    "net = RegressResNet3d().cuda()\n",
    "loss_fn = nn.SmoothL1Loss().cuda()\n",
    "#lr = 1e-2\n",
    "#optim = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "lr = 1e-3\n",
    "#optim = torch.optim.SGD([{'params': net.fc.weight, 'lr': 1e-2}], lr=lr)\n",
    "optim = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "epoch = 100\n",
    "train_loader = DataLoader(train_set, batch_size=8)\n",
    "val_loader = DataLoader(val_set, batch_size=8)\n",
    "for i in range(epoch):\n",
    "    total_loss = 0\n",
    "    predy = np.array([])\n",
    "    y = np.array([])\n",
    "    net.train()\n",
    "    for step, [img, labels, score] in enumerate(train_loader):\n",
    "        img = img.cuda()\n",
    "        labels = labels.cuda()\n",
    "        score = score.cuda()\n",
    "        output = net(img, labels).squeeze(-1)\n",
    "        loss = loss_fn(output, score)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #scheduler.step()\n",
    "        \n",
    "        output = output.cpu().detach().numpy()\n",
    "        score = score.cpu().detach().numpy()\n",
    "        predy = np.concatenate((predy, output), axis=0)\n",
    "        y = np.concatenate((y, score), axis=0)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    nmse = np.sum((y - predy) ** 2) / np.sum(y ** 2)\n",
    "    mse = np.sum((y - predy) ** 2) / len(train_set)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.sum(np.abs(y - predy)) / len(train_set)\n",
    "    meany = np.mean(y)\n",
    "    rsquared = r2_score(y, predy)\n",
    "    print('train epoch {}, loss {}, nmse {}, rmse {}, mae {}, rsquared {}'.format(i, total_loss, nmse, rmse, mae, rsquared))\n",
    "    \n",
    "    if log:\n",
    "        writer.add_scalar('train/Loss', total_loss, i)\n",
    "        writer.add_scalar('train/NMSE', nmse, i)\n",
    "        writer.add_scalar('train/RMSE', rmse, i)\n",
    "        writer.add_scalar('train/MAE', mae, i)\n",
    "        writer.add_scalar('train/rsquared', rsquared, i)\n",
    "        \n",
    "    net.eval()\n",
    "    total_loss = 0\n",
    "    predy = np.array([])\n",
    "    y = np.array([])\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for step, [img, labels, score] in enumerate(val_loader):\n",
    "            img = img.cuda()\n",
    "            labels = labels.cuda()\n",
    "            score = score.cuda()\n",
    "            output = net(img, labels).squeeze(-1)\n",
    "            loss = loss_fn(output, score)\n",
    "\n",
    "            output = output.cpu().detach().numpy()\n",
    "            score = score.cpu().detach().numpy()\n",
    "            #print(\"y: \", score)\n",
    "            #print(\"y_pred: \", output)\n",
    "            predy = np.concatenate((predy, output), axis=0)\n",
    "            y = np.concatenate((y, score), axis=0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    nmse = np.sum((y - predy) ** 2) / np.sum(y ** 2)\n",
    "    mse = np.sum((y - predy) ** 2) / len(val_set)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.sum(np.abs(y - predy)) / len(val_set)\n",
    "    meany = np.mean(y)\n",
    "    rsquared = r2_score(y, predy)\n",
    "    print('validation epoch {}, loss {}, nmse {}, rmse {}, mae {}, rsquared {}'.format(i, total_loss, nmse, rmse, mae, rsquared))\n",
    "    if log:\n",
    "        writer.add_scalar('validation/Loss', total_loss, i)\n",
    "        writer.add_scalar('validation/NMSE', nmse, i)\n",
    "        writer.add_scalar('validation/RMSE', rmse, i)\n",
    "        writer.add_scalar('validation/MAE', mae, i)\n",
    "        writer.add_scalar('validation/rsquared', rsquared, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99, loss 14.81796445565536, nmse 0.38246806504802155, rmse 0.2794655588970451, mae 0.2638362386154233, rsquared -0.5403551487274227\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_set, batch_size=64)\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for step, [img, labels, score] in enumerate(test_loader):\n",
    "        img = img.cuda()\n",
    "        labels = labels.cuda()\n",
    "        score = score.cuda()\n",
    "        #score = torch.Tensor(np.random.randint(0, 3, score.size())).type(torch.LongTensor).cuda()\n",
    "        output = net(img, labels).squeeze(-1)\n",
    "        loss = loss_fn(output, score)\n",
    "        \n",
    "        predy = np.concatenate((predy, output.cpu().detach().numpy()), axis=0)\n",
    "        y = np.concatenate((y, score.cpu().detach().numpy()), axis=0)\n",
    "        total_loss += loss.item()\n",
    "nmse = np.sum((y - predy) ** 2) / np.sum(y ** 2)\n",
    "mse = np.sum((y - predy) ** 2) / len(test_set)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = np.sum(np.abs(y - predy)) / len(test_set)\n",
    "meany = np.mean(y)\n",
    "rsquared = 1 - np.sum((predy - y) ** 2) / np.sum((y - meany) ** 2)\n",
    "print('epoch {}, loss {}, nmse {}, rmse {}, mae {}, rsquared {}'.format(i, total_loss, nmse, rmse, mae, rsquared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.SmoothL1Loss().cuda()\n",
    "lr = 1e-3\n",
    "optim = torch.optim.SGD([\n",
    "    {'params': net.fc.weight, 'lr': 1e-2}\n",
    "    ], lr=lr, momentum=0.3)\n",
    "#optim = torch.optim.SGD(net.parameters(), lr=1e-1, momentum=0.3)\n",
    "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.99)\n",
    "#optim = torch.optim.Adam(net.parameters(), lr=lr, betas=[0.3, 0.1])\n",
    "epoch = 100\n",
    "dataset = BlockRegressDataset('train')\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(dataset)))):\n",
    "    train_sampler = sampler.SubsetRandomSampler(train_idx)\n",
    "    val_sampler = sampler.SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=64, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=64, sampler=val_sampler)\n",
    "    for i in range(epoch):\n",
    "        total_loss = 0\n",
    "        predy = np.array([])\n",
    "        y = np.array([])\n",
    "        net.train()\n",
    "        for step, [img, labels, score] in enumerate(train_loader):\n",
    "            img = img.cuda()\n",
    "            labels = labels.cuda()\n",
    "            score = score.cuda()\n",
    "            output = net(img, labels).squeeze(-1)\n",
    "            loss = loss_fn(output.float(), score.float())\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            #scheduler.step()\n",
    "        \n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for step, [img, labels, score] in enumerate(val_loader):\n",
    "                img = img.cuda()\n",
    "                labels = labels.cuda()\n",
    "                score = score.cuda()\n",
    "                output = net(img, labels).squeeze(-1)\n",
    "                loss = loss_fn(output.float(), score.float())\n",
    "        \n",
    "                predy = np.concatenate((predy, output.cpu().detach().numpy()), axis=0)\n",
    "                y = np.concatenate((y, score.cpu().detach().numpy()), axis=0)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        nmse = np.sum((y - predy) ** 2) / np.sum(y ** 2)\n",
    "        mse = np.sum((y - predy) ** 2) / len(train_idx)\n",
    "        mae = np.sum(np.abs(y - predy)) / len(train_idx)\n",
    "        meany = np.mean(y)\n",
    "        rsquared = np.sum((predy - meany) ** 2) / np.sum((y - meany) ** 2)\n",
    "        print('epoch {}, loss {}, nmse {}, mae {}, rsquared {}'.format(i, total_loss, nmse, mae, rsquared))\n",
    "        writer.add_scalar('Loss', total_loss, i)\n",
    "        writer.add_scalar('NMSE', nmse, i)\n",
    "        writer.add_scalar('MAE', mae, i)\n",
    "        writer.add_scalar('rsquared', rsquared, i)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predy = []\n",
    "y = []\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(dataset)))):\n",
    "    train_sampler = sampler.SubsetRandomSampler(train_idx)\n",
    "    val_sampler = sampler.SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=64, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=64, sampler=val_sampler)\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, [img, labels, score] in enumerate(train_loader):\n",
    "            img = img.cuda()\n",
    "            labels = labels.cuda()\n",
    "            score = score.cuda()\n",
    "            output = net(img, labels).squeeze(-1)\n",
    "            loss = loss_fn(output.float(), score.float())\n",
    "    \n",
    "            predy = np.concatenate((predy, output.cpu().detach().numpy()), axis=0)\n",
    "            y = np.concatenate((y, score.cpu().detach().numpy()), axis=0)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    nmse = np.sum((y - predy) ** 2) / np.sum(y ** 2)\n",
    "    mse = np.sum((y - predy) ** 2) / len(train_idx)\n",
    "    mae = np.sum(np.abs(y - predy)) / len(train_idx)\n",
    "    meany = np.mean(y)\n",
    "    rsquared = np.sum((predy - meany) ** 2) / np.sum((y - meany) ** 2)\n",
    "    print(rsquared)\n",
    "    print(mse)\n",
    "    print(mae)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('3.8.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "420353a47962bc0cada1a6173771095a3d05bd8a3ecc61a5b633bf029926f1ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
