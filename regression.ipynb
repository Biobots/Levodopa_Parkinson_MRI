{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dl.loader import PatchRedressDataset, BlockRegressDataset, BlockClassifyDataset\n",
    "import numpy as np\n",
    "from src.dl.resnet import RegressResNet18, RegressResNet3d\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RegressResNet3d().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "net = torch.load(os.path.join('data', 'bin', 'resnet50.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.SmoothL1Loss().cuda()\n",
    "lr = 1e-3\n",
    "optim = torch.optim.SGD([\n",
    "    {'params': net.fc.weight, 'lr': 1e-2}\n",
    "    ], lr=lr, momentum=0.3)\n",
    "#optim = torch.optim.SGD(net.parameters(), lr=1e-1, momentum=0.3)\n",
    "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.99)\n",
    "#optim = torch.optim.Adam(net.parameters(), lr=lr, betas=[0.3, 0.1])\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BlockRegressDataset('train')\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(dataset)))):\n",
    "    train_sampler = sampler.SubsetRandomSampler(train_idx)\n",
    "    val_sampler = sampler.SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=64, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=64, sampler=val_sampler)\n",
    "    for i in range(epoch):\n",
    "        total_loss = 0\n",
    "        predy = np.array([])\n",
    "        y = np.array([])\n",
    "        net.train()\n",
    "        for step, [img, labels, score] in enumerate(train_loader):\n",
    "            img = img.cuda()\n",
    "            labels = labels.cuda()\n",
    "            score = score.cuda()\n",
    "            output = net(img, labels).squeeze(-1)\n",
    "            loss = loss_fn(output.float(), score.float())\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            #scheduler.step()\n",
    "        \n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for step, [img, labels, score] in enumerate(val_loader):\n",
    "                img = img.cuda()\n",
    "                labels = labels.cuda()\n",
    "                score = score.cuda()\n",
    "                output = net(img, labels).squeeze(-1)\n",
    "                loss = loss_fn(output.float(), score.float())\n",
    "        \n",
    "                predy = np.concatenate((predy, output.cpu().detach().numpy()), axis=0)\n",
    "                y = np.concatenate((y, score.cpu().detach().numpy()), axis=0)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        nmse = np.sum((y - predy) ** 2) / np.sum(y ** 2)\n",
    "        mse = np.sum((y - predy) ** 2) / len(train_idx)\n",
    "        mae = np.sum(np.abs(y - predy)) / len(train_idx)\n",
    "        meany = np.mean(y)\n",
    "        rsquared = np.sum((predy - meany) ** 2) / np.sum((y - meany) ** 2)\n",
    "        print('epoch {}, loss {}, nmse {}, mae {}, rsquared {}'.format(i, total_loss, nmse, mae, rsquared))\n",
    "        writer.add_scalar('Loss', total_loss, i)\n",
    "        writer.add_scalar('NMSE', nmse, i)\n",
    "        writer.add_scalar('MAE', mae, i)\n",
    "        writer.add_scalar('rsquared', rsquared, i)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predy = []\n",
    "y = []\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(dataset)))):\n",
    "    train_sampler = sampler.SubsetRandomSampler(train_idx)\n",
    "    val_sampler = sampler.SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=64, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=64, sampler=val_sampler)\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, [img, labels, score] in enumerate(train_loader):\n",
    "            img = img.cuda()\n",
    "            labels = labels.cuda()\n",
    "            score = score.cuda()\n",
    "            output = net(img, labels).squeeze(-1)\n",
    "            loss = loss_fn(output.float(), score.float())\n",
    "    \n",
    "            predy = np.concatenate((predy, output.cpu().detach().numpy()), axis=0)\n",
    "            y = np.concatenate((y, score.cpu().detach().numpy()), axis=0)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    nmse = np.sum((y - predy) ** 2) / np.sum(y ** 2)\n",
    "    mse = np.sum((y - predy) ** 2) / len(train_idx)\n",
    "    mae = np.sum(np.abs(y - predy)) / len(train_idx)\n",
    "    meany = np.mean(y)\n",
    "    rsquared = np.sum((predy - meany) ** 2) / np.sum((y - meany) ** 2)\n",
    "    print(rsquared)\n",
    "    print(mse)\n",
    "    print(mae)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('3.8.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "420353a47962bc0cada1a6173771095a3d05bd8a3ecc61a5b633bf029926f1ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
