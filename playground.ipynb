{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dl.loader import BlockClassifyDataset\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.data import getPandas, writePandas\n",
    "data = getPandas('data')\n",
    "test = data.sample(frac=0.2, random_state=10)\n",
    "data = data.drop(test.index)\n",
    "validate = data.sample(frac=0.1, random_state=10)\n",
    "train = data.drop(validate.index)\n",
    "test = test.reset_index(drop=True)\n",
    "train = train.reset_index(drop=True)\n",
    "validate = validate.reset_index(drop=True)\n",
    "writePandas('data_test', test)\n",
    "writePandas('data_train', train)\n",
    "writePandas('data_validate', validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dl.loader import BlockClassifyDataset\n",
    "from src.dl.resnet import ClassifyResNet3d\n",
    "from sklearn.model_selection import KFold\n",
    "import collections\n",
    "bounds = [0.2, 0.4]\n",
    "train_set = BlockClassifyDataset('train', bounds)\n",
    "val_set = BlockClassifyDataset('validate', bounds)\n",
    "test_set = BlockClassifyDataset('test', bounds)\n",
    "fold_num = 5\n",
    "kf = KFold(n_splits=fold_num, shuffle=True, random_state=10)\n",
    "best_models = np.empty(dtype=collections.OrderedDict, shape=fold_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 54.833759129047394, acc 18.181818181818183%\n",
      "epoch 1, loss 94.96752627938986, acc 28.576751117734723%\n",
      "epoch 2, loss 1406.1079279333353, acc 29.247391952309986%\n",
      "epoch 3, loss 169.45163141585363, acc 45.34277198211625%\n",
      "epoch 4, loss 190.50428378582, acc 24.81371087928465%\n",
      "epoch 5, loss 62.69731676578522, acc 34.46348733233979%\n",
      "epoch 6, loss 51.01551115512848, acc 35.581222056631894%\n",
      "epoch 7, loss 50.47101449966431, acc 36.36363636363637%\n",
      "epoch 8, loss 51.260402500629425, acc 36.36363636363637%\n",
      "epoch 9, loss 53.407276690006256, acc 36.36363636363637%\n",
      "epoch 10, loss 51.32100212574005, acc 36.36363636363637%\n",
      "epoch 11, loss 50.90332415699959, acc 36.36363636363637%\n",
      "epoch 12, loss 49.80819883942604, acc 40.90909090909091%\n",
      "epoch 13, loss 49.99594974517822, acc 40.90909090909091%\n",
      "epoch 14, loss 52.938422441482544, acc 36.36363636363637%\n",
      "epoch 15, loss 52.47132992744446, acc 36.32637853949329%\n",
      "epoch 16, loss 52.57668870687485, acc 27.384500745156483%\n",
      "epoch 17, loss 51.313000082969666, acc 36.36363636363637%\n",
      "epoch 18, loss 46.062449872493744, acc 40.90909090909091%\n",
      "epoch 19, loss 50.55524191260338, acc 40.90909090909091%\n",
      "epoch 20, loss 46.17826917767525, acc 41.02086438152012%\n",
      "epoch 21, loss 47.893832206726074, acc 40.90909090909091%\n",
      "epoch 22, loss 47.83170533180237, acc 40.90909090909091%\n",
      "epoch 23, loss 45.81401717662811, acc 40.90909090909091%\n",
      "epoch 24, loss 48.74634239077568, acc 40.90909090909091%\n",
      "epoch 25, loss 50.68551489710808, acc 40.90909090909091%\n",
      "epoch 26, loss 52.503711611032486, acc 31.818181818181817%\n",
      "epoch 27, loss 46.68309199810028, acc 40.90909090909091%\n",
      "epoch 28, loss 46.97175848484039, acc 45.45454545454545%\n",
      "epoch 29, loss 48.79886385798454, acc 40.90909090909091%\n",
      "epoch 30, loss 47.05608195066452, acc 40.90909090909091%\n",
      "epoch 31, loss 47.601217836141586, acc 40.90909090909091%\n",
      "epoch 32, loss 51.8909766972065, acc 36.36363636363637%\n",
      "epoch 33, loss 47.9793835580349, acc 40.90909090909091%\n",
      "epoch 34, loss 43.13147112727165, acc 50.0%\n",
      "epoch 35, loss 49.327283412218094, acc 40.90909090909091%\n",
      "epoch 36, loss 49.317515671253204, acc 40.7973174366617%\n",
      "epoch 37, loss 46.22466707229614, acc 40.90909090909091%\n",
      "epoch 38, loss 46.10113799571991, acc 40.90909090909091%\n",
      "epoch 39, loss 50.23251849412918, acc 40.90909090909091%\n"
     ]
    }
   ],
   "source": [
    "net = ClassifyResNet3d(len(bounds)+1).cuda()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "lr = 1e-2\n",
    "optim = torch.optim.Adam(net.parameters(), lr=lr, betas=[0.9, 0.99])\n",
    "epoch = 40\n",
    "train_loader = DataLoader(train_set, batch_size=64)\n",
    "val_loader = DataLoader(val_set, batch_size=64)\n",
    "best_acc = 0\n",
    "for i in range(epoch):\n",
    "    total_loss = 0\n",
    "    predy = np.array([])\n",
    "    y = np.array([])\n",
    "    net.train()\n",
    "    for step, [img, labels, score] in enumerate(train_loader):\n",
    "        img = img.cuda()\n",
    "        labels = labels.cuda()\n",
    "        score = score.cuda()\n",
    "        output = net(img, labels)\n",
    "        loss = loss_fn(output, score)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #scheduler.step()\n",
    "        \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for step, [img, labels, score] in enumerate(val_loader):\n",
    "            img = img.cuda()\n",
    "            labels = labels.cuda()\n",
    "            score = score.cuda()\n",
    "            output = net(img, labels)\n",
    "            loss = loss_fn(output, score)\n",
    "                \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += score.size(0)\n",
    "            correct += np.sum(predicted.cpu().detach().numpy() == score.cpu().detach().numpy())\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print('epoch {}, loss {}, acc {}%'.format(i, total_loss, acc))\n",
    "    writer.add_scalar('Loss', total_loss, i)\n",
    "    writer.add_scalar('ACC', acc, i)\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 174.0620468556881, acc 42.57741347905282%\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_set, batch_size=64)\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for step, [img, labels, score] in enumerate(test_loader):\n",
    "        img = img.cuda()\n",
    "        labels = labels.cuda()\n",
    "        score = score.cuda()\n",
    "        #score = torch.Tensor(np.random.randint(0, 3, score.size())).type(torch.LongTensor).cuda()\n",
    "        output = net(img, labels)\n",
    "        loss = loss_fn(output, score)\n",
    "        \n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += score.size(0)\n",
    "        correct += np.sum(predicted.cpu().detach().numpy() == score.cpu().detach().numpy())\n",
    "        total_loss += loss.item()\n",
    "acc = 100 * correct / total\n",
    "print('loss {}, acc {}%'.format(total_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0, epoch 0, loss 25.36275154352188, acc 52.2289156626506%\n",
      "fold 0, epoch 1, loss 25.79340159893036, acc 53.01204819277108%\n",
      "fold 0, epoch 2, loss 66.44929361343384, acc 45.903614457831324%\n",
      "fold 0, epoch 3, loss 8.27451991289854, acc 88.55421686746988%\n",
      "fold 0, epoch 4, loss 16.002849817276, acc 80.60240963855422%\n",
      "fold 0, epoch 5, loss 2.3077152324840426, acc 95.12048192771084%\n",
      "fold 0, epoch 6, loss 4.3462723679840565, acc 93.07228915662651%\n",
      "fold 0, epoch 7, loss 3.69453813880682, acc 93.01204819277109%\n",
      "fold 0, epoch 8, loss 136.72240436077118, acc 76.56626506024097%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m net\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m step, [img, labels, score] \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m---> 18\u001b[0m     img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mcuda()\n\u001b[0;32m     19\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     20\u001b[0m     score \u001b[39m=\u001b[39m score\u001b[39m.\u001b[39mcuda()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(train_set)))):\n",
    "    net = ClassifyResNet3d(len(bounds)+1).cuda()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    lr = 1e-2\n",
    "    optim = torch.optim.Adam(net.parameters(), lr=lr, betas=[0.9, 0.99])\n",
    "    epoch = 40\n",
    "    train_sampler = sampler.SubsetRandomSampler(train_idx)\n",
    "    val_sampler = sampler.SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(train_set, batch_size=64, sampler=train_sampler)\n",
    "    val_loader = DataLoader(train_set, batch_size=64, sampler=val_sampler)\n",
    "    best_acc = 0\n",
    "    for i in range(epoch):\n",
    "        total_loss = 0\n",
    "        predy = np.array([])\n",
    "        y = np.array([])\n",
    "        net.train()\n",
    "        for step, [img, labels, score] in enumerate(train_loader):\n",
    "            img = img.cuda()\n",
    "            labels = labels.cuda()\n",
    "            score = score.cuda()\n",
    "            output = net(img, labels)\n",
    "            loss = loss_fn(output, score)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            #scheduler.step()\n",
    "        \n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for step, [img, labels, score] in enumerate(val_loader):\n",
    "                img = img.cuda()\n",
    "                labels = labels.cuda()\n",
    "                score = score.cuda()\n",
    "                output = net(img, labels)\n",
    "                loss = loss_fn(output, score)\n",
    "                \n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += score.size(0)\n",
    "                correct += np.sum(predicted.cpu().detach().numpy() == score.cpu().detach().numpy())\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        if acc >= best_acc:\n",
    "            best_acc = acc\n",
    "            best_models[fold] = copy.deepcopy(net.state_dict())\n",
    "        print('fold {}, epoch {}, loss {}, acc {}%'.format(fold, i, total_loss, acc))\n",
    "        #writer.add_scalar('Loss/loss'+str(fold), total_loss, i)\n",
    "        #writer.add_scalar('ACC/acc'+str(fold), acc, i)\n",
    "    best_acc = 0\n",
    "    break\n",
    "\n",
    "#writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('3.8.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "420353a47962bc0cada1a6173771095a3d05bd8a3ecc61a5b633bf029926f1ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
