{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dl.loader import BlockClassifyDataset\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'fold_num'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcollections\u001b[39;00m\n\u001b[0;32m      5\u001b[0m bounds \u001b[39m=\u001b[39m [\u001b[39m0.2\u001b[39m, \u001b[39m0.5\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m train_set \u001b[39m=\u001b[39m BlockClassifyDataset(\u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m, bounds)\n\u001b[0;32m      7\u001b[0m fold_num \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m      8\u001b[0m kf \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39mfold_num, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'fold_num'"
     ]
    }
   ],
   "source": [
    "from src.dl.loader import BlockClassifyDataset\n",
    "from src.dl.resnet import ClassifyResNet3d\n",
    "from sklearn.model_selection import KFold\n",
    "import collections\n",
    "bounds = [0.2, 0.5]\n",
    "train_set = BlockClassifyDataset('test', bounds)\n",
    "fold_num = 5\n",
    "kf = KFold(n_splits=fold_num, shuffle=True, random_state=10)\n",
    "best_models = np.empty(dtype=collections.OrderedDict, shape=fold_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0, epoch 0, loss 25.36275154352188, acc 52.2289156626506%\n",
      "fold 0, epoch 1, loss 25.79340159893036, acc 53.01204819277108%\n",
      "fold 0, epoch 2, loss 66.44929361343384, acc 45.903614457831324%\n",
      "fold 0, epoch 3, loss 8.27451991289854, acc 88.55421686746988%\n",
      "fold 0, epoch 4, loss 16.002849817276, acc 80.60240963855422%\n",
      "fold 0, epoch 5, loss 2.3077152324840426, acc 95.12048192771084%\n",
      "fold 0, epoch 6, loss 4.3462723679840565, acc 93.07228915662651%\n",
      "fold 0, epoch 7, loss 3.69453813880682, acc 93.01204819277109%\n",
      "fold 0, epoch 8, loss 136.72240436077118, acc 76.56626506024097%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m net\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m step, [img, labels, score] \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m---> 18\u001b[0m     img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mcuda()\n\u001b[0;32m     19\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     20\u001b[0m     score \u001b[39m=\u001b[39m score\u001b[39m.\u001b[39mcuda()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(train_set)))):\n",
    "    net = ClassifyResNet3d(len(bounds)+1).cuda()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    lr = 1e-2\n",
    "    optim = torch.optim.Adam(net.parameters(), lr=lr, betas=[0.9, 0.99])\n",
    "    epoch = 40\n",
    "    train_sampler = sampler.SubsetRandomSampler(train_idx)\n",
    "    val_sampler = sampler.SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(train_set, batch_size=64, sampler=train_sampler)\n",
    "    val_loader = DataLoader(train_set, batch_size=64, sampler=val_sampler)\n",
    "    best_acc = 0\n",
    "    for i in range(epoch):\n",
    "        total_loss = 0\n",
    "        predy = np.array([])\n",
    "        y = np.array([])\n",
    "        net.train()\n",
    "        for step, [img, labels, score] in enumerate(train_loader):\n",
    "            img = img.cuda()\n",
    "            labels = labels.cuda()\n",
    "            score = score.cuda()\n",
    "            output = net(img, labels)\n",
    "            loss = loss_fn(output, score)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            #scheduler.step()\n",
    "        \n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for step, [img, labels, score] in enumerate(val_loader):\n",
    "                img = img.cuda()\n",
    "                labels = labels.cuda()\n",
    "                score = score.cuda()\n",
    "                output = net(img, labels)\n",
    "                loss = loss_fn(output, score)\n",
    "                \n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += score.size(0)\n",
    "                correct += np.sum(predicted.cpu().detach().numpy() == score.cpu().detach().numpy())\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        if acc >= best_acc:\n",
    "            best_acc = acc\n",
    "            best_models[fold] = copy.deepcopy(net.state_dict())\n",
    "        print('fold {}, epoch {}, loss {}, acc {}%'.format(fold, i, total_loss, acc))\n",
    "        #writer.add_scalar('Loss/loss'+str(fold), total_loss, i)\n",
    "        #writer.add_scalar('ACC/acc'+str(fold), acc, i)\n",
    "    best_acc = 0\n",
    "    break\n",
    "\n",
    "#writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 3659.054661643261, acc 42.23132969034609%\n"
     ]
    }
   ],
   "source": [
    "test_set = BlockClassifyDataset('train', bounds)\n",
    "test_loader = DataLoader(test_set, batch_size=64)\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for step, [img, labels, score] in enumerate(test_loader):\n",
    "        img = img.cuda()\n",
    "        labels = labels.cuda()\n",
    "        score = score.cuda()\n",
    "        output = net(img, labels)\n",
    "        loss = loss_fn(output, score)\n",
    "        \n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += score.size(0)\n",
    "        correct += np.sum(predicted.cpu().detach().numpy() == score.cpu().detach().numpy())\n",
    "        total_loss += loss.item()\n",
    "acc = 100 * correct / total\n",
    "print('loss {}, acc {}%'.format(total_loss, acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('3.8.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "420353a47962bc0cada1a6173771095a3d05bd8a3ecc61a5b633bf029926f1ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
