{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dl.loader import BlockClassifyDataset\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "import copy\n",
    "log = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = True\n",
    "writer = SummaryWriter('./log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.data import getPandas, writePandas\n",
    "data = getPandas('data')\n",
    "test = data.sample(frac=0.2, random_state=10)\n",
    "data = data.drop(test.index)\n",
    "validate = data.sample(frac=0.1, random_state=10)\n",
    "train = data.drop(validate.index)\n",
    "test = test.reset_index(drop=True)\n",
    "train = train.reset_index(drop=True)\n",
    "validate = validate.reset_index(drop=True)\n",
    "writePandas('data_test', test)\n",
    "writePandas('data_train', train)\n",
    "writePandas('data_validate', validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dl.loader import BlockClassifyDataset\n",
    "from src.dl.resnet import ClassifyResNet3d\n",
    "from sklearn.model_selection import KFold\n",
    "import collections\n",
    "bounds = [0.3]\n",
    "train_set = BlockClassifyDataset('train', bounds)\n",
    "val_set = BlockClassifyDataset('validate', bounds)\n",
    "test_set = BlockClassifyDataset('test', bounds)\n",
    "fold_num = 5\n",
    "kf = KFold(n_splits=fold_num, shuffle=True, random_state=10)\n",
    "best_models = np.empty(dtype=collections.OrderedDict, shape=fold_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 70.02419054508209, acc 57.407407407407405%\n",
      "epoch 1, loss 68.95704737305641, acc 61.171827565270185%\n",
      "epoch 2, loss 69.11325097084045, acc 57.407407407407405%\n",
      "epoch 3, loss 74.66052442789078, acc 51.56344869459623%\n",
      "epoch 4, loss 69.81718823313713, acc 59.25925925925926%\n",
      "epoch 5, loss 73.16472232341766, acc 46.2962962962963%\n",
      "epoch 6, loss 73.7607578933239, acc 42.592592592592595%\n",
      "epoch 7, loss 72.89858666062355, acc 44.44444444444444%\n",
      "epoch 8, loss 72.47053182125092, acc 46.2962962962963%\n",
      "epoch 9, loss 71.76597332954407, acc 48.148148148148145%\n",
      "epoch 10, loss 70.4279714524746, acc 55.55555555555556%\n",
      "epoch 11, loss 71.35358560085297, acc 51.851851851851855%\n",
      "epoch 12, loss 70.45460456609726, acc 55.55555555555556%\n",
      "epoch 13, loss 70.23517709970474, acc 55.55555555555556%\n",
      "epoch 14, loss 68.52003109455109, acc 61.111111111111114%\n",
      "epoch 15, loss 67.64775881171227, acc 62.96296296296296%\n",
      "epoch 16, loss 68.59790870547295, acc 61.111111111111114%\n",
      "epoch 17, loss 66.74712625145912, acc 61.111111111111114%\n",
      "epoch 18, loss 67.50490897893906, acc 62.96296296296296%\n",
      "epoch 19, loss 67.08032938838005, acc 61.111111111111114%\n",
      "epoch 20, loss 66.0219278037548, acc 64.81481481481481%\n",
      "epoch 21, loss 66.97889032959938, acc 64.81481481481481%\n",
      "epoch 22, loss 65.3668996989727, acc 70.37037037037037%\n",
      "epoch 23, loss 66.12986922264099, acc 61.111111111111114%\n",
      "epoch 24, loss 65.59061074256897, acc 62.96296296296296%\n",
      "epoch 25, loss 65.62659734487534, acc 61.111111111111114%\n",
      "epoch 26, loss 66.62032768130302, acc 62.96296296296296%\n",
      "epoch 27, loss 64.93027994036674, acc 70.37037037037037%\n",
      "epoch 28, loss 64.81966736912727, acc 68.51851851851852%\n",
      "epoch 29, loss 66.77452164888382, acc 62.96296296296296%\n",
      "epoch 30, loss 64.70407947897911, acc 66.66666666666667%\n",
      "epoch 31, loss 65.27107998728752, acc 62.96296296296296%\n",
      "epoch 32, loss 65.50202357769012, acc 66.66666666666667%\n",
      "epoch 33, loss 67.16877171397209, acc 59.25925925925926%\n",
      "epoch 34, loss 64.65490904450417, acc 66.66666666666667%\n",
      "epoch 35, loss 64.46720093488693, acc 64.81481481481481%\n",
      "epoch 36, loss 64.55877190828323, acc 66.66666666666667%\n",
      "epoch 37, loss 64.44525730609894, acc 66.66666666666667%\n",
      "epoch 38, loss 65.84111969172955, acc 62.96296296296296%\n",
      "epoch 39, loss 64.57245165109634, acc 66.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "net = ClassifyResNet3d(len(bounds)+1).cuda()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "lr = 1e-2\n",
    "optim = torch.optim.Adam(net.parameters(), lr=lr, betas=[0.9, 0.99])\n",
    "epoch = 40\n",
    "train_loader = DataLoader(train_set, batch_size=64)\n",
    "test_loader = DataLoader(test_set, batch_size=64)\n",
    "best_acc = 0\n",
    "for i in range(epoch):\n",
    "    total_loss = 0\n",
    "    predy = np.array([])\n",
    "    y = np.array([])\n",
    "    net.train()\n",
    "    for step, [img, labels, score] in enumerate(train_loader):\n",
    "        img = img.cuda()\n",
    "        labels = labels.cuda()\n",
    "        score = score.cuda()\n",
    "        output = net(img, labels)\n",
    "        loss = loss_fn(output, score)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #scheduler.step()\n",
    "        \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for step, [img, labels, score] in enumerate(test_loader):\n",
    "            img = img.cuda()\n",
    "            labels = labels.cuda()\n",
    "            score = score.cuda()\n",
    "            output = net(img, labels)\n",
    "            loss = loss_fn(output, score)\n",
    "                \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += score.size(0)\n",
    "            correct += np.sum(predicted.cpu().detach().numpy() == score.cpu().detach().numpy())\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print('epoch {}, loss {}, acc {}%'.format(i, total_loss, acc))\n",
    "    if log:\n",
    "        writer.add_scalar('Loss', total_loss, i)\n",
    "        writer.add_scalar('ACC', acc, i)\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 155.1054586172104, acc 77.27272727272727%\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(val_set, batch_size=64)\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for step, [img, labels, score] in enumerate(test_loader):\n",
    "        img = img.cuda()\n",
    "        labels = labels.cuda()\n",
    "        score = score.cuda()\n",
    "        #score = torch.Tensor(np.random.randint(0, 3, score.size())).type(torch.LongTensor).cuda()\n",
    "        output = net(img, labels)\n",
    "        loss = loss_fn(output, score)\n",
    "        \n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += score.size(0)\n",
    "        correct += np.sum(predicted.cpu().detach().numpy() == score.cpu().detach().numpy())\n",
    "        total_loss += loss.item()\n",
    "acc = 100 * correct / total\n",
    "print('loss {}, acc {}%'.format(total_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0, epoch 0, loss 25.36275154352188, acc 52.2289156626506%\n",
      "fold 0, epoch 1, loss 25.79340159893036, acc 53.01204819277108%\n",
      "fold 0, epoch 2, loss 66.44929361343384, acc 45.903614457831324%\n",
      "fold 0, epoch 3, loss 8.27451991289854, acc 88.55421686746988%\n",
      "fold 0, epoch 4, loss 16.002849817276, acc 80.60240963855422%\n",
      "fold 0, epoch 5, loss 2.3077152324840426, acc 95.12048192771084%\n",
      "fold 0, epoch 6, loss 4.3462723679840565, acc 93.07228915662651%\n",
      "fold 0, epoch 7, loss 3.69453813880682, acc 93.01204819277109%\n",
      "fold 0, epoch 8, loss 136.72240436077118, acc 76.56626506024097%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m net\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m step, [img, labels, score] \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m---> 18\u001b[0m     img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mcuda()\n\u001b[0;32m     19\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     20\u001b[0m     score \u001b[39m=\u001b[39m score\u001b[39m.\u001b[39mcuda()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(train_set)))):\n",
    "    net = ClassifyResNet3d(len(bounds)+1).cuda()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    lr = 1e-2\n",
    "    optim = torch.optim.Adam(net.parameters(), lr=lr, betas=[0.9, 0.99])\n",
    "    epoch = 40\n",
    "    train_sampler = sampler.SubsetRandomSampler(train_idx)\n",
    "    val_sampler = sampler.SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(train_set, batch_size=64, sampler=train_sampler)\n",
    "    val_loader = DataLoader(train_set, batch_size=64, sampler=val_sampler)\n",
    "    best_acc = 0\n",
    "    for i in range(epoch):\n",
    "        total_loss = 0\n",
    "        predy = np.array([])\n",
    "        y = np.array([])\n",
    "        net.train()\n",
    "        for step, [img, labels, score] in enumerate(train_loader):\n",
    "            img = img.cuda()\n",
    "            labels = labels.cuda()\n",
    "            score = score.cuda()\n",
    "            output = net(img, labels)\n",
    "            loss = loss_fn(output, score)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            #scheduler.step()\n",
    "        \n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for step, [img, labels, score] in enumerate(val_loader):\n",
    "                img = img.cuda()\n",
    "                labels = labels.cuda()\n",
    "                score = score.cuda()\n",
    "                output = net(img, labels)\n",
    "                loss = loss_fn(output, score)\n",
    "                \n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += score.size(0)\n",
    "                correct += np.sum(predicted.cpu().detach().numpy() == score.cpu().detach().numpy())\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        if acc >= best_acc:\n",
    "            best_acc = acc\n",
    "            best_models[fold] = copy.deepcopy(net.state_dict())\n",
    "        print('fold {}, epoch {}, loss {}, acc {}%'.format(fold, i, total_loss, acc))\n",
    "        #writer.add_scalar('Loss/loss'+str(fold), total_loss, i)\n",
    "        #writer.add_scalar('ACC/acc'+str(fold), acc, i)\n",
    "    best_acc = 0\n",
    "    break\n",
    "\n",
    "#writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('3.8.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "420353a47962bc0cada1a6173771095a3d05bd8a3ecc61a5b633bf029926f1ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
